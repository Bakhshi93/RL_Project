{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Formulating the problem as an MDP "
      ],
      "metadata": {
        "id": "Fqskx3kvr6TX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QflciZyEN4UQ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.read_csv('Final_Datasetnew.csv')\n",
        "df2 = pd.read_csv('Final_Datasetnew2.csv')\n",
        "data = pd.concat([df1, df2])\n",
        "data.head()\n",
        "data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFrirPriSOBd",
        "outputId": "16c10ca5-c578-4bf7-d56f-e6a038e6281b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 6558 entries, 0 to 4431\n",
            "Data columns (total 4 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   State       6558 non-null   int64  \n",
            " 1   Action      6558 non-null   object \n",
            " 2   Reward      6558 non-null   int64  \n",
            " 3   Next_State  6558 non-null   float64\n",
            "dtypes: float64(1), int64(2), object(1)\n",
            "memory usage: 256.2+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Need to label encode the actions \n",
        "# Positive - 2\n",
        "# Neutral - 1\n",
        "# Negative - 0 \n",
        "\n",
        "from sklearn import preprocessing\n",
        "label_encoder = preprocessing.LabelEncoder()\n",
        "data['Action'] = label_encoder.fit_transform(data['Action'])\n",
        "print(data['Action'].unique())\n",
        "data.head(5)"
      ],
      "metadata": {
        "id": "ChdMbyuXXW5P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "outputId": "b420adef-c126-4b09-e61f-fd3a9c167852"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 2 0]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   State  Action  Reward  Next_State\n",
              "0      1       1      -1         1.0\n",
              "1      1       1      10         2.0\n",
              "2      2       1      10         2.0\n",
              "3      2       1      -1         1.0\n",
              "4      1       1      10         2.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-429b4d71-8c2c-4488-a015-b9ef19abd78a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>State</th>\n",
              "      <th>Action</th>\n",
              "      <th>Reward</th>\n",
              "      <th>Next_State</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-429b4d71-8c2c-4488-a015-b9ef19abd78a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-429b4d71-8c2c-4488-a015-b9ef19abd78a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-429b4d71-8c2c-4488-a015-b9ef19abd78a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Action 0"
      ],
      "metadata": {
        "id": "P9lEZB5HaN5C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "action0 = (data['Action'] == 0).sum()\n",
        "action1 = (data['Action'] == 1).sum()\n",
        "action2 = (data['Action'] == 2).sum()\n",
        "\n",
        "act0st1 = data[(data['Action'] == 0) & (data['State'] == 1)]\n",
        "\n",
        "act0pr1_1 = data[(data['Action'] == 0) & (data['State'] == 1) & \n",
        "              (data['Next_State'] == 1)]              \n",
        "act0pr1_2 = data[(data['Action'] == 0) & (data['State'] == 1) & \n",
        "              (data['Next_State'] == 2)]\n",
        "act0pr1_3 = data[(data['Action'] == 0) & (data['State'] == 1) & \n",
        "              (data['Next_State'] == 3)]\n",
        "act0pr1_4 = data[(data['Action'] == 0) & (data['State'] == 1) & \n",
        "              (data['Next_State'] == 4)] \n",
        "\n",
        "pr0_1_1 = len(act0pr1_1)/len(act0st1)\n",
        "pr0_1_2 = len(act0pr1_2)/len(act0st1)\n",
        "pr0_1_3 = len(act0pr1_3)/len(act0st1)\n",
        "pr0_1_4 = len(act0pr1_4)/len(act0st1)\n",
        "\n",
        "act0st2 = data[(data['Action'] == 0) & (data['State'] == 2)]\n",
        "\n",
        "act0pr2_1 = data[(data['Action'] == 0) & (data['State'] == 2) & \n",
        "              (data['Next_State'] == 1)]\n",
        "act0pr2_2 = data[(data['Action'] == 0) & (data['State'] == 2) & \n",
        "              (data['Next_State'] == 2)]\n",
        "act0pr2_3 = data[(data['Action'] == 0) & (data['State'] == 2) & \n",
        "              (data['Next_State'] == 3)]\n",
        "act0pr2_4 = data[(data['Action'] == 0) & (data['State'] == 2) & \n",
        "              (data['Next_State'] == 4)] \n",
        "\n",
        "pr0_2_1 = len(act0pr2_1)/len(act0st2)\n",
        "pr0_2_2 = len(act0pr2_2)/len(act0st2)\n",
        "pr0_2_3 = len(act0pr2_3)/len(act0st2)\n",
        "pr0_2_4 = len(act0pr2_4)/len(act0st2)\n",
        "\n",
        "act0st3 = data[(data['Action'] == 0) & (data['State'] == 3)]\n",
        "\n",
        "act0pr3_1 = data[(data['Action'] == 0) & (data['State'] == 3) & \n",
        "              (data['Next_State'] == 1)]\n",
        "act0pr3_2 = data[(data['Action'] == 0) & (data['State'] == 3) & \n",
        "              (data['Next_State'] == 2)]\n",
        "act0pr3_3 = data[(data['Action'] == 0) & (data['State'] == 3) & \n",
        "              (data['Next_State'] == 3)]\n",
        "act0pr3_4 = data[(data['Action'] == 0) & (data['State'] == 3) & \n",
        "              (data['Next_State'] == 4)]\n",
        "\n",
        "pr0_3_1 = len(act0pr3_1)/len(act0st3)\n",
        "pr0_3_2 = len(act0pr3_2)/len(act0st3)\n",
        "pr0_3_3 = len(act0pr3_3)/len(act0st3)\n",
        "pr0_3_4 = len(act0pr3_4)/len(act0st3)\n",
        "\n",
        "act0st4 = data[(data['Action'] == 0) & (data['State'] == 4)]\n",
        "\n",
        "act0pr4_1 = data[(data['Action'] == 0) & (data['State'] == 4) & \n",
        "              (data['Next_State'] == 1)]\n",
        "act0pr4_2 = data[(data['Action'] == 0) & (data['State'] == 4) & \n",
        "              (data['Next_State'] == 2)]\n",
        "act0pr4_3 = data[(data['Action'] == 0) & (data['State'] == 4) & \n",
        "              (data['Next_State'] == 3)]\n",
        "act0pr4_4 = data[(data['Action'] == 0) & (data['State'] == 4) & \n",
        "              (data['Next_State'] == 4)]\n",
        "\n",
        "pr0_4_1 = len(act0pr4_1)/len(act0st4)\n",
        "pr0_4_2 = len(act0pr4_2)/len(act0st4)\n",
        "pr0_4_3 = len(act0pr4_3)/len(act0st4)\n",
        "pr0_4_4 = len(act0pr4_4)/len(act0st4)\n"
      ],
      "metadata": {
        "id": "koUMYSf6OQZa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Action 1"
      ],
      "metadata": {
        "id": "JLeMFsnfaJJ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "act1st1 = data[(data['Action'] == 1) & (data['State'] == 1)]\n",
        "\n",
        "act1pr1_1 = data[(data['Action'] == 1) & (data['State'] == 1) & \n",
        "              (data['Next_State'] == 1)]              \n",
        "act1pr1_2 = data[(data['Action'] == 1) & (data['State'] == 1) & \n",
        "              (data['Next_State'] == 2)]\n",
        "act1pr1_3 = data[(data['Action'] == 1) & (data['State'] == 1) & \n",
        "              (data['Next_State'] == 3)]\n",
        "act1pr1_4 = data[(data['Action'] == 1) & (data['State'] == 1) & \n",
        "              (data['Next_State'] == 4)] \n",
        "\n",
        "pr1_1_1 = len(act1pr1_1)/len(act1st1)\n",
        "pr1_1_2 = len(act1pr1_2)/len(act1st1)\n",
        "pr1_1_3 = len(act1pr1_3)/len(act1st1)\n",
        "pr1_1_4 = len(act1pr1_4)/len(act1st1)\n",
        "\n",
        "act1st2 = data[(data['Action'] == 1) & (data['State'] == 2)]\n",
        "\n",
        "act1pr2_1 = data[(data['Action'] == 1) & (data['State'] == 2) & \n",
        "              (data['Next_State'] == 1)]\n",
        "act1pr2_2 = data[(data['Action'] == 1) & (data['State'] == 2) & \n",
        "              (data['Next_State'] == 2)]\n",
        "act1pr2_3 = data[(data['Action'] == 1) & (data['State'] == 2) & \n",
        "              (data['Next_State'] == 3)]\n",
        "act1pr2_4 = data[(data['Action'] == 1) & (data['State'] == 2) & \n",
        "              (data['Next_State'] == 4)] \n",
        "\n",
        "pr1_2_1 = len(act1pr2_1)/len(act1st2)\n",
        "pr1_2_2 = len(act1pr2_2)/len(act1st2)\n",
        "pr1_2_3 = len(act1pr2_3)/len(act1st2)\n",
        "pr1_2_4 = len(act1pr2_4)/len(act1st2)\n",
        "\n",
        "act1st3 = data[(data['Action'] == 1) & (data['State'] == 3)]\n",
        "\n",
        "act1pr3_1 = data[(data['Action'] == 1) & (data['State'] == 3) & \n",
        "              (data['Next_State'] == 1)]\n",
        "act1pr3_2 = data[(data['Action'] == 1) & (data['State'] == 3) & \n",
        "              (data['Next_State'] == 2)]\n",
        "act1pr3_3 = data[(data['Action'] == 1) & (data['State'] == 3) & \n",
        "              (data['Next_State'] == 3)]\n",
        "act1pr3_4 = data[(data['Action'] == 1) & (data['State'] == 3) & \n",
        "              (data['Next_State'] == 4)]\n",
        "\n",
        "pr1_3_1 = len(act1pr3_1)/len(act1st3)\n",
        "pr1_3_2 = len(act1pr3_2)/len(act1st3)\n",
        "pr1_3_3 = len(act1pr3_3)/len(act1st3)\n",
        "pr1_3_4 = len(act1pr3_4)/len(act1st3)\n",
        "\n",
        "act1st4 = data[(data['Action'] == 1) & (data['State'] == 4)]\n",
        "\n",
        "act1pr4_1 = data[(data['Action'] == 1) & (data['State'] == 4) & \n",
        "              (data['Next_State'] == 1)]\n",
        "act1pr4_2 = data[(data['Action'] == 1) & (data['State'] == 4) & \n",
        "              (data['Next_State'] == 2)]\n",
        "act1pr4_3 = data[(data['Action'] == 1) & (data['State'] == 4) & \n",
        "              (data['Next_State'] == 3)]\n",
        "act1pr4_4 = data[(data['Action'] == 1) & (data['State'] == 4) & \n",
        "              (data['Next_State'] == 4)]\n",
        "\n",
        "pr1_4_1 = len(act1pr4_1)/len(act1st4)\n",
        "pr1_4_2 = len(act1pr4_2)/len(act1st4)\n",
        "pr1_4_3 = len(act1pr4_3)/len(act1st4)\n",
        "pr1_4_4 = len(act1pr4_4)/len(act1st4)"
      ],
      "metadata": {
        "id": "VGxESV40aGZ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Action 2"
      ],
      "metadata": {
        "id": "2jYPPO1-W6aa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "act2st1 = data[(data['Action'] == 2) & (data['State'] == 1)]\n",
        "\n",
        "act2pr1_1 = data[(data['Action'] == 2) & (data['State'] == 1) & \n",
        "              (data['Next_State'] == 1)]              \n",
        "act2pr1_2 = data[(data['Action'] == 2) & (data['State'] == 1) & \n",
        "              (data['Next_State'] == 2)]\n",
        "act2pr1_3 = data[(data['Action'] == 2) & (data['State'] == 1) & \n",
        "              (data['Next_State'] == 3)]\n",
        "act2pr1_4 = data[(data['Action'] == 2) & (data['State'] == 1) & \n",
        "              (data['Next_State'] == 4)] \n",
        "\n",
        "pr2_1_1 = len(act2pr1_1)/len(act2st1)\n",
        "pr2_1_2 = len(act2pr1_2)/len(act2st1)\n",
        "pr2_1_3 = len(act2pr1_3)/len(act2st1)\n",
        "pr2_1_4 = len(act2pr1_4)/len(act2st1)\n",
        "\n",
        "act2st2 = data[(data['Action'] == 2) & (data['State'] == 2)]\n",
        "\n",
        "act2pr2_1 = data[(data['Action'] == 2) & (data['State'] == 2) & \n",
        "              (data['Next_State'] == 1)]\n",
        "act2pr2_2 = data[(data['Action'] == 2) & (data['State'] == 2) & \n",
        "              (data['Next_State'] == 2)]\n",
        "act2pr2_3 = data[(data['Action'] == 2) & (data['State'] == 2) & \n",
        "              (data['Next_State'] == 3)]\n",
        "act2pr2_4 = data[(data['Action'] == 2) & (data['State'] == 2) & \n",
        "              (data['Next_State'] == 4)] \n",
        "\n",
        "pr2_2_1 = len(act2pr2_1)/len(act2st2)\n",
        "pr2_2_2 = len(act2pr2_2)/len(act2st2)\n",
        "pr2_2_3 = len(act2pr2_3)/len(act2st2)\n",
        "pr2_2_4 = len(act2pr2_4)/len(act2st2)\n",
        "\n",
        "act2st3 = data[(data['Action'] == 2) & (data['State'] == 3)]\n",
        "\n",
        "act2pr3_1 = data[(data['Action'] == 2) & (data['State'] == 3) & \n",
        "              (data['Next_State'] == 1)]\n",
        "act2pr3_2 = data[(data['Action'] == 2) & (data['State'] == 3) & \n",
        "              (data['Next_State'] == 2)]\n",
        "act2pr3_3 = data[(data['Action'] == 2) & (data['State'] == 3) & \n",
        "              (data['Next_State'] == 3)]\n",
        "act2pr3_4 = data[(data['Action'] == 2) & (data['State'] == 3) & \n",
        "              (data['Next_State'] == 4)]\n",
        "\n",
        "pr2_3_1 = len(act2pr3_1)/len(act2st3)\n",
        "pr2_3_2 = len(act2pr3_2)/len(act2st3)\n",
        "pr2_3_3 = len(act2pr3_3)/len(act2st3)\n",
        "pr2_3_4 = len(act2pr3_4)/len(act2st3)\n",
        "\n",
        "act2st4 = data[(data['Action'] == 2) & (data['State'] == 4)]\n",
        "\n",
        "act2pr4_1 = data[(data['Action'] == 2) & (data['State'] == 4) & \n",
        "              (data['Next_State'] == 1)]\n",
        "act2pr4_2 = data[(data['Action'] == 2) & (data['State'] == 4) & \n",
        "              (data['Next_State'] == 2)]\n",
        "act2pr4_3 = data[(data['Action'] == 2) & (data['State'] == 4) & \n",
        "              (data['Next_State'] == 3)]\n",
        "act2pr4_4 = data[(data['Action'] == 2) & (data['State'] == 4) & \n",
        "              (data['Next_State'] == 4)]\n",
        "\n",
        "pr2_4_1 = len(act2pr4_1)/len(act2st4)\n",
        "pr2_4_2 = len(act2pr4_2)/len(act2st4)\n",
        "pr2_4_3 = len(act2pr4_3)/len(act2st4)\n",
        "pr2_4_4 = len(act2pr4_4)/len(act2st4)"
      ],
      "metadata": {
        "id": "6SP5IPsEaHdS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "class MDP:\n",
        "    '''A simple MDP class.  It includes the following members'''\n",
        "\n",
        "    def __init__(self, T, R, discount):\n",
        "        '''Constructor for the MDP class\n",
        "\n",
        "        Inputs:\n",
        "        T -- Transition function: |A| x |S| x |S'| array\n",
        "        R -- Reward function: |A| x |S| array\n",
        "        discount -- discount factor: scalar in [0,1)\n",
        "\n",
        "        The constructor verifies that the inputs are valid and sets\n",
        "        corresponding variables in a MDP object'''\n",
        "\n",
        "        assert T.ndim == 3, \"Invalid transition function: it should have 3 dimensions\"\n",
        "        self.nActions = T.shape[0]\n",
        "        self.nStates = T.shape[1]\n",
        "        assert T.shape == (\n",
        "        self.nActions, self.nStates, self.nStates), \"Invalid transition function: it has dimensionality \" + repr(\n",
        "            T.shape) + \", but it should be (nActions,nStates,nStates)\"\n",
        "        assert (abs(T.sum(\n",
        "            2) - 1) < 1e-5).all(), \"Invalid transition function: some transition probability does not equal 1\"\n",
        "        self.T = T\n",
        "        assert R.ndim == 2, \"Invalid reward function: it should have 2 dimensions\"\n",
        "        assert R.shape == (self.nActions, self.nStates), \"Invalid reward function: it has dimensionality \" + repr(\n",
        "            R.shape) + \", but it should be (nActions,nStates)\"\n",
        "        self.R = R\n",
        "        assert 0 <= discount < 1, \"Invalid discount factor: it should be in [0,1)\"\n",
        "        self.discount = discount\n",
        "\n",
        "    def valueIteration(self, initialV, nIterations=np.inf, tolerance=0.01):\n",
        "        '''Value iteration procedure\n",
        "        V <-- max_a R^a + gamma T^a V\n",
        "\n",
        "        Inputs:\n",
        "        initialV -- Initial value function: array of |S| entries\n",
        "        nIterations -- limit on the # of iterations: scalar (default: infinity)\n",
        "        tolerance -- threshold on ||V^n-V^n+1||_inf: scalar (default: 0.01)\n",
        "\n",
        "        Outputs: \n",
        "        V -- Value function: array of |S| entries\n",
        "        iterId -- # of iterations performed: scalar\n",
        "        epsilon -- ||V^n-V^n+1||_inf: scalar'''\n",
        "\n",
        "        V = initialV\n",
        "        iterId = 0\n",
        "        epsilon = np.inf\n",
        "        policy = np.zeros(len(initialV), dtype=int)\n",
        "\n",
        "        \"\"\"\n",
        "        print(\"===========================================================================\")\n",
        "        print(\"Executing Value Iteration\")\n",
        "        print(\"--------------------------------------------\")\n",
        "        \"\"\"\n",
        "\n",
        "        while iterId < nIterations and epsilon > tolerance:\n",
        "            Ta_V = np.matmul(self.T, V)\n",
        "            gamma_Ta_V = self.discount * Ta_V\n",
        "            all_possible_values = self.R + gamma_Ta_V\n",
        "            policy = np.argmax(all_possible_values, axis=0)  # Choose the best actions for each state, policy means keep\n",
        "            V_new = np.amax((all_possible_values), axis=0)  # Choose the best action values for each state\n",
        "            # np.round/np.around does not work for 0.5 so not reducing to 2 decimal places\n",
        "            V_diff = (V_new - V)\n",
        "            V = V_new\n",
        "            epsilon = np.linalg.norm(V_diff, np.inf)\n",
        "            #computes the maximum absolute value of the elements in the V_diff array and stores the result in the variable epsilon\n",
        "            #print(\"Iteration : \" + str(iterId) + \" V : \" + str(V) + \" Policy: \" + str(policy) + \" epsilon: \" + str(epsilon))\n",
        "            iterId = iterId + 1\n",
        "\n",
        "        \"\"\"\n",
        "        print(\"--------------------------------------------\")\n",
        "        print(\"Final State values after \" + str(iterId) + \" iterations , V: \" + str(V) + \" Policy: \" + str(policy))\n",
        "        print(\"===========================================================================\")\n",
        "        \"\"\"\n",
        "\n",
        "        return [V, iterId, epsilon]\n",
        "\n",
        "    def extractPolicy(self, V):\n",
        "        '''Procedure to extract a policy from a value function\n",
        "        pi <-- argmax_a R^a + gamma T^a V\n",
        "\n",
        "        Inputs:\n",
        "        V -- Value function: array of |S| entries\n",
        "\n",
        "        Output:\n",
        "        policy -- Policy: array of |S| entries'''\n",
        "\n",
        "        \"\"\"\n",
        "        print(\"***************************************************************\")\n",
        "        print(\"Executing Policy Extraction\")\n",
        "        print(\"--------------------------------------------\")\n",
        "        \"\"\"\n",
        "\n",
        "        all_possible_values = (self.R + (self.discount*(np.matmul(self.T, V))))  # Get values for all possible state transition in this state\n",
        "\n",
        "        \"\"\"\n",
        "        print(\"All Values for All possible state transition: \")\n",
        "        print(all_possible_values)\n",
        "        \"\"\"\n",
        "\n",
        "        policy = np.argmax(all_possible_values, axis=0)  # Choose the best actions for each state, policy means keep\n",
        "\n",
        "        \"\"\"\n",
        "        print(\"Extracted Policy : \" + str(policy))\n",
        "        print(\"--------------------------------------------\")\n",
        "        \"\"\"\n",
        "\n",
        "        \"\"\"\n",
        "        # track of action chosen at timestamp t, instead of choosing only value\n",
        "        max_values = [all_possible_values[policy[i]][i] for i in range(len(policy))]\n",
        "        print(\"Values Corresponding to Selected Policies: \" + str(max_values))\n",
        "        print(\"***************************************************************\")\n",
        "        \"\"\"\n",
        "\n",
        "        return policy\n",
        "\n",
        "    def evaluatePolicy(self, policy):\n",
        "        '''Evaluate a policy by solving a system of linear equations\n",
        "        V^pi = R^pi + gamma T^pi V^pi\n",
        "\n",
        "        Input:\n",
        "        policy -- Policy: array of |S| entries\n",
        "\n",
        "        Ouput:\n",
        "        V -- Value function: array of |S| entries'''\n",
        "\n",
        "        \"\"\"\n",
        "        print(\"***************************************************************\")\n",
        "        print(\"Executing Policy Evaluation\")\n",
        "        print(\"--------------------------------------------\")\n",
        "        print(\"Policy : \" + str(policy))\n",
        "        print(\"Evaluating a policy by solving a system of linear equations\")\n",
        "        \"\"\"\n",
        "\n",
        "        R_policy = np.array([self.R[policy[i]][i] for i in range(len(policy))])\n",
        "        T_policy = np.array([self.T[policy[i]][i] for i in range(len(policy))])\n",
        "        gamma_T_policy = self.discount * T_policy\n",
        "        assert gamma_T_policy.shape[0] == gamma_T_policy.shape[1], \"gamma_T_policy matrix should be square\"\n",
        "        V = np.matmul(np.linalg.inv(np.identity(len(policy)) - gamma_T_policy), R_policy)\n",
        "\n",
        "        \"\"\"\n",
        "        print(\"V : \" + str(V))\n",
        "        print(\"***************************************************************\")\n",
        "        \"\"\"\n",
        "\n",
        "        return V\n",
        "\n",
        "    def policyIteration(self, initialPolicy, nIterations=np.inf):\n",
        "        '''Policy iteration procedure: alternate between policy\n",
        "        evaluation (solve V^pi = R^pi + gamma T^pi V^pi) and policy\n",
        "        improvement (pi <-- argmax_a R^a + gamma T^a V^pi).\n",
        "\n",
        "        Inputs:\n",
        "        initialPolicy -- Initial policy: array of |S| entries\n",
        "        nIterations -- limit on # of iterations: scalar (default: inf)\n",
        "\n",
        "        Outputs: \n",
        "        policy -- Policy: array of |S| entries\n",
        "        V -- Value function: array of |S| entries\n",
        "        iterId -- # of iterations peformed by modified policy iteration: scalar'''\n",
        "\n",
        "        policy = initialPolicy  # np.zeros(self.nStates)\n",
        "        V = np.zeros(self.nStates)\n",
        "        iterId = 0\n",
        "\n",
        "        \"\"\"\n",
        "        print(\"===========================================================================\")\n",
        "        print(\"Executing Policy Iteration\")\n",
        "        print(\"--------------------------------------------\")\n",
        "        \"\"\"\n",
        "\n",
        "        while iterId < nIterations:\n",
        "            V = self.evaluatePolicy(policy)\n",
        "            #print(\"Iteration : \" + str(iterId) + \" V : \" + str(V) + \" policy : \" + str(policy))\n",
        "\n",
        "            policy_new = self.extractPolicy(V)\n",
        "            iterId = iterId + 1\n",
        "\n",
        "            if np.array_equal(policy_new, policy):\n",
        "                break\n",
        "\n",
        "            policy = policy_new\n",
        "\n",
        "        \"\"\"\n",
        "        print(\"Iteration : \" + str(iterId) + \" V : \" + str(V) + \" policy : \" + str(policy))\n",
        "        print(\"--------------------------------------------\")\n",
        "        print(\"Final policy after \" + str(iterId) + \" iterations , policy: \" + str(policy))\n",
        "        print(\"===========================================================================\")\n",
        "        \"\"\"\n",
        "\n",
        "        return [policy, V, iterId]\n",
        "\n",
        "    def evaluatePolicyPartially(self, policy, initialV, nIterations=np.inf, tolerance=0.01):\n",
        "        '''Partial policy evaluation:\n",
        "        Repeat V^pi <-- R^pi + gamma T^pi V^pi\n",
        "\n",
        "        Inputs:\n",
        "        policy -- Policy: array of |S| entries\n",
        "        initialV -- Initial value function: array of |S| entries\n",
        "        nIterations -- limit on the # of iterations: scalar (default: infinity)\n",
        "        tolerance -- threshold on ||V^n-V^n+1||_inf: scalar (default: 0.01)\n",
        "\n",
        "        Outputs: \n",
        "        V -- Value function: array of |S| entries\n",
        "        iterId -- # of iterations performed: scalar\n",
        "        epsilon -- ||V^n-V^n+1||_inf: scalar'''\n",
        "\n",
        "        # temporary values to ensure that the code compiles until this\n",
        "        # function is coded\n",
        "        V = initialV  # np.zeros(self.nStates)\n",
        "        iterId = 0\n",
        "        epsilon = np.inf\n",
        "\n",
        "        \"\"\"\n",
        "        print(\"***************************************************************\")\n",
        "        print(\"Executing Partial Policy Evaluation\")\n",
        "        print(\"--------------------------------------------\")\n",
        "        print(\"Policy : \" + str(policy))\n",
        "        print(\"Evaluating a policy by repeating \" + str(nIterations) + \" times.\")\n",
        "        print(\"Iteration : \" + str(iterId) + \" V : \" + str(V) + \" Policy: \" + str(policy))\n",
        "        \"\"\"\n",
        "\n",
        "        while iterId < nIterations and epsilon > tolerance:\n",
        "            iterId = iterId+1\n",
        "            R_policy = np.array([self.R[policy[i]][i] for i in range(len(policy))])\n",
        "            T_policy = np.array([self.T[policy[i]][i] for i in range(len(policy))])\n",
        "            Vnew = R_policy + (self.discount * np.matmul(T_policy, V))\n",
        "            epsilon = np.linalg.norm((Vnew-V), np.inf)\n",
        "            V = Vnew\n",
        "\n",
        "            #print(\"Iteration : \" + str(iterId) + \" V : \" + str(V) + \" Policy: \" + str(policy) + \" epsilon : \" + str(epsilon))\n",
        "\n",
        "        \"\"\"\n",
        "        print(\"V : \" + str(V))\n",
        "        print(\"***************************************************************\")\n",
        "        \"\"\"\n",
        "\n",
        "        return [V, iterId, epsilon]\n",
        "\n",
        "    def modifiedPolicyIteration(self, initialPolicy, initialV, nEvalIterations=5, nIterations=np.inf, tolerance=0.01):\n",
        "        '''Modified policy iteration procedure: alternate between\n",
        "        partial policy evaluation (repeat a few times V^pi <-- R^pi + gamma T^pi V^pi)\n",
        "        and policy improvement (pi <-- argmax_a R^a + gamma T^a V^pi)\n",
        "\n",
        "        Inputs:\n",
        "        initialPolicy -- Initial policy: array of |S| entries\n",
        "        initialV -- Initial value function: array of |S| entries\n",
        "        nEvalIterations -- limit on # of iterations to be performed in each partial policy evaluation: scalar (default: 5)\n",
        "        nIterations -- limit on # of iterations to be performed in modified policy iteration: scalar (default: inf)\n",
        "        tolerance -- threshold on ||V^n-V^n+1||_inf: scalar (default: 0.01)\n",
        "\n",
        "        Outputs: \n",
        "        policy -- Policy: array of |S| entries\n",
        "        V -- Value function: array of |S| entries\n",
        "        iterId -- # of iterations peformed by modified policy iteration: scalar\n",
        "        epsilon -- ||V^n-V^n+1||_inf: scalar'''\n",
        "\n",
        "        # temporary values to ensure that the code compiles until this\n",
        "        # function is coded\n",
        "        policy = initialPolicy\n",
        "        V = initialV\n",
        "        iterId = 0\n",
        "        epsilon = np.inf\n",
        "\n",
        "        \"\"\"\n",
        "        print(\"===========================================================================\")\n",
        "        print(\"Executing Modified Policy Iteration\")\n",
        "        print(\"--------------------------------------------\")\n",
        "        print(\"Iteration : \" + str(iterId) + \" policy : \" + str(policy))\n",
        "        \"\"\"\n",
        "\n",
        "        while iterId < nIterations and epsilon > tolerance:\n",
        "            iterId = iterId + 1\n",
        "            Vn, _ , _  = self.evaluatePolicyPartially(policy, V, nEvalIterations, tolerance)\n",
        "            #print(\"Vn : \" + str(Vn))\n",
        "            all_possible_values = (self.R + (self.discount * np.matmul(self.T,Vn)))  # Get values for all possible state transition in this state\n",
        "            policy = np.argmax(all_possible_values, axis=0)  # Choose the best actions for each state, policy means keep\n",
        "\n",
        "            Vn_plus_1 = [all_possible_values[policy[i]][i] for i in range(len(policy))]\n",
        "            V_diff = (Vn_plus_1 - Vn)\n",
        "            V = Vn_plus_1\n",
        "            epsilon = np.linalg.norm(V_diff, np.inf)\n",
        "            #print(\"Iteration : \" + str(iterId) + \" policy : \" + str(policy))\n",
        "\n",
        "        \"\"\"\n",
        "        print(\"--------------------------------------------\")\n",
        "        print(\"Final policy after \" + str(iterId) + \" iterations , policy: \" + str(policy))\n",
        "        print(\"===========================================================================\")\n",
        "        \"\"\"\n",
        "\n",
        "        return [policy, V, iterId, epsilon]\n"
      ],
      "metadata": {
        "id": "p4lmg10afJpf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' Construct simple MDP as described in Lecture 1b Slides 17-18'''\n",
        "# Transition function: |A| x |S| x |S'| array\n",
        "T = np.array([[[pr0_1_1,pr0_1_2,pr0_1_3,pr0_1_4],[pr0_2_1,pr0_2_2,pr0_2_3,pr0_2_4],\n",
        "               [pr0_3_1,pr0_3_2,pr0_3_3,pr0_3_4],[pr0_4_1,pr0_4_2,pr0_4_3,pr0_4_4]],\n",
        "              [[pr1_1_1,pr1_1_2,pr1_1_3,pr1_1_4],[pr1_2_1,pr1_2_2,pr1_2_3,pr1_2_4],\n",
        "               [pr1_3_1,pr1_3_2,pr1_3_3,pr1_3_4],[pr1_4_1,pr1_4_2,pr1_4_3,pr1_4_4]],\n",
        "              [[pr2_1_1,pr2_1_2,pr2_1_3,pr2_1_4],[pr2_2_1,pr2_2_2,pr2_2_3,pr2_2_4],\n",
        "               [pr2_3_1,pr2_3_2,pr2_3_3,pr2_3_4],[pr2_4_1,pr2_4_2,pr2_4_3,pr2_4_4]]])\n",
        "# Reward function: |A| x |S| array\n",
        "R = np.array([[-1, 10, 25, 50],[-1, 10, 25, 50],[-1, 10, 25, 50]])\n",
        "# Discount factor: scalar in [0,1)\n",
        "discount = 0.9        \n",
        "# MDP object\n",
        "mdp = MDP(T,R,discount)"
      ],
      "metadata": {
        "id": "ZH2i1chIfadn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(T.round(3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3vRIaz8R5Eu",
        "outputId": "e55d14f1-6b8d-44f1-c9ff-b0487f45dac6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[0.398 0.304 0.216 0.082]\n",
            "  [0.202 0.441 0.282 0.075]\n",
            "  [0.115 0.345 0.403 0.137]\n",
            "  [0.157 0.241 0.422 0.181]]\n",
            "\n",
            " [[0.331 0.352 0.248 0.068]\n",
            "  [0.156 0.474 0.293 0.076]\n",
            "  [0.113 0.363 0.415 0.109]\n",
            "  [0.133 0.273 0.411 0.184]]\n",
            "\n",
            " [[0.495 0.297 0.168 0.04 ]\n",
            "  [0.179 0.538 0.243 0.04 ]\n",
            "  [0.309 0.336 0.289 0.066]\n",
            "  [0.133 0.556 0.244 0.067]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''Test each procedure'''\n",
        "[V,nIterations,epsilon] = mdp.valueIteration(initialV=np.zeros(mdp.nStates))\n",
        "policy = mdp.extractPolicy(V)\n",
        "print(\"V : \" , V.round(3))\n",
        "print(\"nIterations : \" + str(nIterations))\n",
        "print(\"Policy : \" + str(policy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFM8RjpEhjmT",
        "outputId": "e5f52d49-a53b-4dd0-dd09-520b3a230d0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "V :  [150.513 164.936 185.041 211.898]\n",
            "nIterations : 72\n",
            "Policy : [1 1 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "V = mdp.evaluatePolicy(np.array([1,0,1,0]))\n",
        "print(\"Value corresponding to policy [1,0,1,0]: \" + str(V))\n",
        "\n",
        "V = mdp.evaluatePolicy(np.array([2,2,2,1]))\n",
        "print(\"Value corresponding to policy [0,1,1,1]: \" + str(V))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csiKD42choLS",
        "outputId": "ce5f33ae-0e41-42d2-a4ce-a140048607e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Value corresponding to policy [1,0,1,0]: [144.7717929  158.23464583 178.14885809 205.8092465 ]\n",
            "Value corresponding to policy [0,1,1,1]: [106.32655538 123.13235676 137.91020339 172.41315478]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[policy,V,iterId] = mdp.policyIteration(np.array([0,0,0,0]))\n",
        "print(\"V : \" + str(V))\n",
        "print(\"nIterations : \" + str(iterId))\n",
        "print(\"Epsilon : \" + str(policy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtH__p6NhwW7",
        "outputId": "49a883a7-f1b1-4de7-f9ee-96644c9cee06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "V : [150.60117771 165.0247759  185.12940029 211.98662109]\n",
            "nIterations : 2\n",
            "Epsilon : [1 1 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[V,iterId,epsilon] = mdp.evaluatePolicyPartially(np.array([1,0,1,0]),np.array([0,10,0,13]))\n",
        "[policy,V,iterId,tolerance] = mdp.modifiedPolicyIteration(np.array([1,0,1,0]),np.array([0,10,0,13]))\n",
        "print(\"V : \" + str(V))\n",
        "print(\"nIterations : \" + str(iterId))\n",
        "print(\"Policy : \" + str(policy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h2PoolvGh4AM",
        "outputId": "c01b6692-59ee-4d77-d968-7c55acea4a8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "V : [150.51337920236205, 164.93697739051854, 185.04160178266346, 211.8988225857995]\n",
            "nIterations : 12\n",
            "Policy : [1 1 0 1]\n"
          ]
        }
      ]
    }
  ]
}